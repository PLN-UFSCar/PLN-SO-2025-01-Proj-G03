{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RUBfEGdEfcrV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUBfEGdEfcrV",
    "outputId": "57e358b7-e0bd-4686-ec6b-95c7b70fb501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wn in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: httpx in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from wn) (0.28.1)\n",
      "Requirement already satisfied: tomli in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from wn) (2.2.1)\n",
      "Requirement already satisfied: anyio in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from httpx->wn) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from httpx->wn) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from httpx->wn) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from httpx->wn) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from httpcore==1.*->httpx->wn) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from anyio->httpx->wn) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages (from anyio->httpx->wn) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4ba3fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d4ba3fd",
    "outputId": "4cb67d86-f574-4df3-bdcf-aa1768730d14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[KSkipping own-pt:1.0.0 (OpenWordnet-PT); already added\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wn\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import string\n",
    "wn.add(\"own-pt.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ca9da5",
   "metadata": {
    "id": "e5ca9da5"
   },
   "outputs": [],
   "source": [
    "def pre_processamento(frase):\n",
    "  frase = frase.lower()\n",
    "  frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "  return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795e4ff6",
   "metadata": {
    "id": "795e4ff6"
   },
   "outputs": [],
   "source": [
    "class WSD:\n",
    "    def __init__(self):\n",
    "        self.extractor = pipeline(\n",
    "            \"feature-extraction\",\n",
    "            model=\"neuralmind/bert-base-portuguese-cased\",\n",
    "            tokenizer=\"neuralmind/bert-base-portuguese-cased\",\n",
    "            framework=\"pt\"\n",
    "        )\n",
    "\n",
    "    def gerarEmbeddingSentido(self, sentido):\n",
    "        #Combinando token CLS e a media dos embeddings do sentido\n",
    "        embs = self.extractor(sentido)[0]\n",
    "        embs = np.array(embs)\n",
    "\n",
    "        embscls = embs[0]\n",
    "        embssentido = np.mean(embs[1:-1], axis=0)\n",
    "\n",
    "        return  (0.8 * embscls + 0.2 * embssentido)\n",
    "        #Usando so token CLS\n",
    "        #  embs = self.extractor(sentido)[0]\n",
    "        #  return embs[0]\n",
    "\n",
    "    def gerarEmbeddingsPalavra(self, contexto, palavra):\n",
    "        tkscontexto = self.extractor.tokenizer.tokenize(contexto)\n",
    "        tkspalavra = self.extractor.tokenizer.tokenize(palavra)\n",
    "\n",
    "        indicespalavra = self.acharPalavraContexto(tkscontexto, tkspalavra)\n",
    "\n",
    "        if not indicespalavra:\n",
    "            print(f\"Palavra '{palavra}' não encontrada no contexto\")\n",
    "            return None\n",
    "\n",
    "        embscontexto = self.extractor(contexto)[0]\n",
    "\n",
    "        indicespalavrasajustado = [i + 1 for i in indicespalavra]\n",
    "\n",
    "        embspalavra = [embscontexto[i] for i in indicespalavrasajustado]\n",
    "\n",
    "        return np.mean(embspalavra, axis=0)\n",
    "\n",
    "    def acharPalavraContexto(self, tkscontexto, tkspalavra):\n",
    "        for i in range(len(tkscontexto) - len(tkspalavra) + 1):\n",
    "            if tkscontexto[i:i+len(tkspalavra)] == tkspalavra:\n",
    "                return list(range(i, i + len(tkspalavra)))\n",
    "        return []\n",
    "\n",
    "    def compararPalavraSentido(self, contexto, palavra, sentido):\n",
    "        embspalavra = self.gerarEmbeddingsPalavra(contexto, palavra)\n",
    "        embssentido = self.gerarEmbeddingSentido(sentido)\n",
    "        if embspalavra is None:\n",
    "            return 0.0\n",
    "        return cosine_similarity([embspalavra], [embssentido])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e296a4",
   "metadata": {
    "id": "d9e296a4"
   },
   "outputs": [],
   "source": [
    "class OWNPT:\n",
    "    def getSenses(self, word):\n",
    "        senses = wn.senses(word)\n",
    "        sensesstr = []\n",
    "        for sense in senses:\n",
    "            definicao = sense.synset().definition()\n",
    "            if definicao:\n",
    "                sensesstr.append(definicao)\n",
    "        return sensesstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bbc0a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75bbc0a3",
    "outputId": "ba17baed-8c8f-4b31-f69b-a767e3cf9f94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.67\n",
      "Precisão (macro): 0.60\n",
      "Revocação (macro): 0.66\n",
      "F1-score (macro): 0.59\n"
     ]
    }
   ],
   "source": [
    "wsd = WSD()\n",
    "ownpt = OWNPT()\n",
    "\n",
    "nomes_das_colunas = ['frase', 'palavra', 'sentido']\n",
    "corpus = pd.read_csv('corpus2teste_revisado_multi.csv', sep=',', on_bad_lines='skip', names=nomes_das_colunas)\n",
    "corpus['sentido'] = corpus['sentido'].apply(lambda x: x.split('|'))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "corpus.head()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for idx, row in corpus.iterrows():\n",
    "    frase = pre_processamento(row['frase'])\n",
    "    palavra = row['palavra']\n",
    "    sentidosreais = row['sentido']\n",
    "\n",
    "    maior_sim = -1\n",
    "    melhor_sentido = None\n",
    "\n",
    "    senses = ownpt.getSenses(palavra)\n",
    "\n",
    "    for sentido_candidato in senses:\n",
    "        sim = wsd.compararPalavraSentido(frase, palavra, pre_processamento(sentido_candidato))\n",
    "        if sim is not None and sim > maior_sim:\n",
    "            maior_sim = sim\n",
    "            melhor_sentido = sentido_candidato\n",
    "\n",
    "    if melhor_sentido:\n",
    "        if melhor_sentido in sentidosreais:\n",
    "            y_true.append(melhor_sentido)\n",
    "        else:\n",
    "            y_true.append(sentidosreais[0])\n",
    "        y_pred.append(melhor_sentido)\n",
    "\n",
    "#print(\"Relatório de classificação:\")\n",
    "#print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Acurácia: {accuracy:.2f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "print(f\"Precisão (macro): {precision:.2f}\")\n",
    "print(f\"Revocação (macro): {recall:.2f}\")\n",
    "print(f\"F1-score (macro): {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4brMF29Fcn8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4brMF29Fcn8",
    "outputId": "58f6ab11-1092-4deb-ac28-96f2c7ce983a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/paula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Pré Processamento Lesk (remove stopwords)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "def pre_processamento(frase):\n",
    "    frase = frase.lower()\n",
    "    frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = frase.split()\n",
    "    return [w for w in tokens if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ix8UT58X_pA0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ix8UT58X_pA0",
    "outputId": "3dab81b0-2371-4e3c-f6b5-9740bdd63d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Lesk\n",
      "Acurácia: 0.41700404858299595\n",
      "Precisão (macro): 0.26\n",
      "Revocação (macro): 0.41\n",
      "F1-score (macro): 0.28\n"
     ]
    }
   ],
   "source": [
    "# Lesk\n",
    "def lesk(palavra, frase, lexico):\n",
    "    senses = lexico.getSenses(palavra)\n",
    "    contexto = set(pre_processamento(frase))\n",
    "\n",
    "    best_sense = None\n",
    "    max_overlap = -1\n",
    "\n",
    "    for sense in senses:\n",
    "        gloss_words = set(sense.lower().split())\n",
    "        overlap = len(contexto.intersection(gloss_words))\n",
    "\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense\n",
    "\n",
    "corpus = pd.read_csv('corpus2teste_revisado_multi.csv', sep=',', on_bad_lines='skip')\n",
    "corpus.columns = ['frase', 'palavra', 'sentido']\n",
    "corpus['sentido'] = corpus['sentido'].apply(lambda x: x.split('|'))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "resultados = []\n",
    "\n",
    "for _, row in corpus.iterrows():\n",
    "    frase = row['frase']\n",
    "    palavra = row['palavra']\n",
    "    sentidosreais = row['sentido']\n",
    "\n",
    "    sentido_predito = lesk(palavra, frase, ownpt)\n",
    "    if sentido_predito:\n",
    "        if sentido_predito in sentidosreais:\n",
    "            y_true.append(sentido_predito)\n",
    "        else:\n",
    "            y_true.append(sentidosreais[0])\n",
    "        y_pred.append(sentido_predito)\n",
    "\n",
    "    resultados.append({\n",
    "            'frase': frase,\n",
    "            'palavra': palavra,\n",
    "            'sentidos_reais': ' | '.join(sentidosreais),\n",
    "            'sentido_previsto': melhor_sentido,\n",
    "            'similaridade': round(maior_sim, 4)\n",
    "        })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "#print(\"Relatório de classificação:\")\n",
    "#print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# Cálculo das métricas\n",
    "print(\"--Lesk\")\n",
    "print(\"Acurácia:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "print(f\"Precisão (macro): {precision:.2f}\")\n",
    "print(f\"Revocação (macro): {recall:.2f}\")\n",
    "print(f\"F1-score (macro): {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Iz_EgX0iEfkv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "Iz_EgX0iEfkv",
    "outputId": "62db900a-8cf4-4f84-ee2a-c3e0fe1451fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados onde o sentido real é diferente do previsto, ordenados pela maior similaridade:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase</th>\n",
       "      <th>palavra</th>\n",
       "      <th>sentidos_reais</th>\n",
       "      <th>sentido_previsto</th>\n",
       "      <th>similaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>As ondas de rádio podem viajar por longas distâncias antes de serem captadas.</td>\n",
       "      <td>viajar</td>\n",
       "      <td>viajar atraves ou sobre uma area</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ele esperou por mais de uma hora no banco desconfortável do lado de fora do consultório.</td>\n",
       "      <td>banco</td>\n",
       "      <td>um assento longo para mais de uma pessoa</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O banco de madeira da varanda precisa de uma nova camada de verniz.</td>\n",
       "      <td>banco</td>\n",
       "      <td>um assento longo para mais de uma pessoa</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Preciso ir ao banco para sacar dinheiro antes da viagem.</td>\n",
       "      <td>banco</td>\n",
       "      <td>uma instituição financeira que aceita depósitos e canaliza o dinheiro em atividades de empréstimo</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O banco central anunciou que a taxa de juros permanecerá estável este mês.</td>\n",
       "      <td>banco</td>\n",
       "      <td>uma instituição financeira que aceita depósitos e canaliza o dinheiro em atividades de empréstimo</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Havia uma pequena inscrição quase ilegível no fundo da antiga caixa de madeira.</td>\n",
       "      <td>fundo</td>\n",
       "      <td>o lado inferior de qualquer coisa</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ele procurou as chaves do carro no fundo da mochila e não as encontrou.</td>\n",
       "      <td>fundo</td>\n",
       "      <td>o lado inferior de qualquer coisa</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Toda a sua teoria foi construída com base em premissas que se provaram falsas.</td>\n",
       "      <td>base</td>\n",
       "      <td>os pressupostos fundamentais dos quais algo é iniciado ou desenvolvido ou calculado ou explicado</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O cálculo da estimativa populacional teve como base os dados do último censo.</td>\n",
       "      <td>base</td>\n",
       "      <td>os pressupostos fundamentais dos quais algo é iniciado ou desenvolvido ou calculado ou explicado</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O advogado argumentou que a acusação não tinha qualquer base legal.</td>\n",
       "      <td>base</td>\n",
       "      <td>os pressupostos fundamentais dos quais algo é iniciado ou desenvolvido ou calculado ou explicado</td>\n",
       "      <td>ir a certos lugares para passear</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        frase  \\\n",
       "493             As ondas de rádio podem viajar por longas distâncias antes de serem captadas.   \n",
       "0    Ele esperou por mais de uma hora no banco desconfortável do lado de fora do consultório.   \n",
       "1                         O banco de madeira da varanda precisa de uma nova camada de verniz.   \n",
       "2                                    Preciso ir ao banco para sacar dinheiro antes da viagem.   \n",
       "3                  O banco central anunciou que a taxa de juros permanecerá estável este mês.   \n",
       "..                                                                                        ...   \n",
       "14            Havia uma pequena inscrição quase ilegível no fundo da antiga caixa de madeira.   \n",
       "13                    Ele procurou as chaves do carro no fundo da mochila e não as encontrou.   \n",
       "12             Toda a sua teoria foi construída com base em premissas que se provaram falsas.   \n",
       "11              O cálculo da estimativa populacional teve como base os dados do último censo.   \n",
       "10                        O advogado argumentou que a acusação não tinha qualquer base legal.   \n",
       "\n",
       "    palavra  \\\n",
       "493  viajar   \n",
       "0     banco   \n",
       "1     banco   \n",
       "2     banco   \n",
       "3     banco   \n",
       "..      ...   \n",
       "14    fundo   \n",
       "13    fundo   \n",
       "12     base   \n",
       "11     base   \n",
       "10     base   \n",
       "\n",
       "                                                                                        sentidos_reais  \\\n",
       "493                                                                   viajar atraves ou sobre uma area   \n",
       "0                                                             um assento longo para mais de uma pessoa   \n",
       "1                                                             um assento longo para mais de uma pessoa   \n",
       "2    uma instituição financeira que aceita depósitos e canaliza o dinheiro em atividades de empréstimo   \n",
       "3    uma instituição financeira que aceita depósitos e canaliza o dinheiro em atividades de empréstimo   \n",
       "..                                                                                                 ...   \n",
       "14                                                                   o lado inferior de qualquer coisa   \n",
       "13                                                                   o lado inferior de qualquer coisa   \n",
       "12    os pressupostos fundamentais dos quais algo é iniciado ou desenvolvido ou calculado ou explicado   \n",
       "11    os pressupostos fundamentais dos quais algo é iniciado ou desenvolvido ou calculado ou explicado   \n",
       "10    os pressupostos fundamentais dos quais algo é iniciado ou desenvolvido ou calculado ou explicado   \n",
       "\n",
       "                     sentido_previsto  similaridade  \n",
       "493  ir a certos lugares para passear        0.2073  \n",
       "0    ir a certos lugares para passear        0.2073  \n",
       "1    ir a certos lugares para passear        0.2073  \n",
       "2    ir a certos lugares para passear        0.2073  \n",
       "3    ir a certos lugares para passear        0.2073  \n",
       "..                                ...           ...  \n",
       "14   ir a certos lugares para passear        0.2073  \n",
       "13   ir a certos lugares para passear        0.2073  \n",
       "12   ir a certos lugares para passear        0.2073  \n",
       "11   ir a certos lugares para passear        0.2073  \n",
       "10   ir a certos lugares para passear        0.2073  \n",
       "\n",
       "[490 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar resultados onde o sentido real é diferente do previsto\n",
    "df_diferentes = df_resultados[df_resultados.apply(lambda row: row['sentido_previsto'] not in row['sentidos_reais'], axis=1)].copy()\n",
    "\n",
    "# Ordenar os resultados filtrados pela similaridade em ordem decrescente\n",
    "df_diferentes_ordenado = df_diferentes.sort_values(by='similaridade', ascending=False)\n",
    "\n",
    "# Exibir o DataFrame filtrado e ordenado\n",
    "print(\"\\nResultados onde o sentido real é diferente do previsto, ordenados pela maior similaridade:\")\n",
    "df_diferentes_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69cf8d84-2d7f-417c-be4c-b31ac0adf1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paula/anaconda3/envs/ambiguidade_env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f7c30d4-a96a-4bc0-bf97-5e92e71d643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "\n",
    "def selecionarSentido(contexto, palavra, wsd, ownpt):\n",
    "    doc = nlp(palavra)\n",
    "    palavra = doc[0].lemma\n",
    "    sentidos = ownpt.getSenses(palavra)\n",
    "\n",
    "    print('Palavra', palavra)\n",
    "    print('Sentidos', sentidos)\n",
    "\n",
    "    # Para ser ambígua, uma palavra precisa ter dois ou mais sentidos\n",
    "    if (sentidos == None or (sentidos != None and len(sentidos) <= 1)):\n",
    "        return None\n",
    "\n",
    "    maior_sim = -1\n",
    "    melhor_sentido = None\n",
    "\n",
    "    for sentido in sentidos:\n",
    "        sim = wsd.compararPalavraSentido(contexto, palavra, pre_processamento(sentido))\n",
    "        if sim is not None and sim > maior_sim:\n",
    "            maior_sim = sim\n",
    "            melhor_sentido = sentido\n",
    "\n",
    "    return melhor_sentido\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
